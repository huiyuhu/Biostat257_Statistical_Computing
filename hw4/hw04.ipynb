{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat M280 Homework 4\n",
    "\n",
    "**Due June 12 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we build a classifer for handwritten digit recognition. Following figure shows example bitmaps of handwritten digits from U.S. postal envelopes. \n",
    "\n",
    "Each digit is represented by a $32 \\times 32$ bitmap in which each element indicates one pixel with a value of white or black. Each $32 \\times 32$ bitmap is divided into blocks of $4 \\times 4$, and the number of white pixels are counted in each block. Therefore each handwritten digit is summarized by a vector $\\mathbf{x} = (x_1, \\ldots, x_{64})$ of length 64 where each element is a count between 0 and 16. \n",
    "\n",
    "We will use a model-based method by assuming a distribution on the count vector and carry out classification using probabilities. A common distribution for count vectors is the multinomial distribution. However as you will see in Q10, it is not a good model for handwritten digits. Let's work on a more flexible model for count vectors. In the Dirichlet-multinomial model, we assume the multinomial probabilities $\\mathbf{p} = (p_1,\\ldots, p_d)$ follow a Dirichlet distribution with parameter vector $\\alpha = (\\alpha_1,\\ldots, \\alpha_d)$, $\\alpha_j>0$, and density\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\\pi(\\mathbf{p}) =  \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1},\n",
    "\\end{eqnarray*} \n",
    "$$\n",
    "where $|\\alpha|=\\sum_{j=1}^d \\alpha_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "For a multivariate count vector $\\mathbf{x}=(x_1,\\ldots,x_d)$ with batch size $|\\mathbf{x}|=\\sum_{j=1}^d x_j$, show that the probability mass function for Dirichlet-multinomial distribution is\n",
    "$$\n",
    "    f(\\mathbf{x} \\mid \\alpha) \n",
    "\t= \\int_{\\Delta_d} \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\pi(\\mathbf{p}) \\, d \\mathbf{p}  \n",
    "    = \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_j)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|+|\\mathbf{x}|)}\n",
    "$$\n",
    "where $\\Delta_d$ is the unit simplex in $d$ dimensions and $|\\alpha| = \\sum_{j=1}^d \\alpha_j$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Pr(\\mathbf{x}\\mid\\boldsymbol{\\alpha})=\\int_{\\mathbf{p}}\\Pr(\\mathbf{x}\\mid \\mathbf{p})\\Pr(\\mathbf{p}\\mid\\boldsymbol{\\alpha})\\textrm{d}\\mathbf{p} $$\n",
    "$$ = \\int_{\\Delta_d} \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\pi(\\mathbf{p}) \\, d \\mathbf{p} $$\n",
    "$$ = \\int_{\\Delta_d} \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j}\\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d \\mathbf{p}  $$\n",
    "$$ = \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\int_{\\Delta_d} \n",
    "\\prod_{j=1}^d p_j^{x_j + \\alpha_j-1} \\, d \\mathbf{p}  $$\n",
    "$$ = \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_j)}{\\Gamma(|\\alpha|+|\\mathbf{x}|)}$$\n",
    "$$ = \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_j)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|+|\\mathbf{x}|)} $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Given independent data points $\\mathbf{x}_1, \\ldots, \\mathbf{x}_n$, show that the log-likelihood is\n",
    "$$\n",
    "L(\\alpha) = \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i} + \\sum_{i=1}^n \\sum_{j=1}^d [\\ln \\Gamma(\\alpha_j + x_{ij}) - \\ln \\Gamma(\\alpha_j)] - \\sum_{i=1}^n [\\ln \\Gamma(|\\alpha|+|\\mathbf{x}_i|) - \\ln \\Gamma(|\\alpha|)].\n",
    "$$\n",
    "Is the log-likelihood a concave function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Write Julia function to compute the log-density of the Dirichlet-multinomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirmult_logpdf1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dirmult_logpdf(x::Vector, α::Vector)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at data point `x`.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(x::Vector, α::Vector)\n",
    "    T = promote_type(eltype(x), eltype(α))\n",
    "    sumx = sum(x)\n",
    "    sumα = sum(α)\n",
    "    if sumx == 0 && sumα == 0\n",
    "        return zero(T)\n",
    "    elseif sumx > 0 && sumα == 0\n",
    "        return convert(T, -Inf)\n",
    "    else\n",
    "        l = lfact(sumx) - lgamma(sumx + sumα) + lgamma(sumα)\n",
    "    end\n",
    "    for i in eachindex(x)\n",
    "        if α[i] == 0 && x[i] > 0\n",
    "            return convert(T, -Inf)\n",
    "        elseif α[i] > 0\n",
    "            l += - lfact(x[i]) + lgamma(x[i] + α[i]) - lgamma(α[i])\n",
    "        end\n",
    "    end\n",
    "    return l\n",
    "end\n",
    "\n",
    "function dirmult_logpdf!(r::Vector, X::Matrix, α::Vector)\n",
    "    for j in 1:size(X, 2)\n",
    "        r[j] = dirmult_logpdf(X[:, j], α)\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    dirmult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function dirmult_logpdf1(X::Matrix, α::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, α)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "  #self# <optimized out>\n",
      "  x::Array{Int64,1}\n",
      "  α::Array{Float64,1}\n",
      "  i::Int64\n",
      "  #temp#@_5::Int64\n",
      "  T <optimized out>\n",
      "  sumx::Int64\n",
      "  sumα::Float64\n",
      "  l::Float64\n",
      "  #temp#@_10::Bool\n",
      "  #temp#@_11::Bool\n",
      "  #temp#@_12::Bool\n",
      "  fy@_13::Float64\n",
      "  fy@_14::Float64\n",
      "  #temp#@_15::Float64\n",
      "  #temp#@_16::Float64\n",
      "  fy@_17::Float64\n",
      "  fx::Float64\n",
      "  #temp#@_19::Float64\n",
      "  #temp#@_20::Float64\n",
      "\n",
      "Body:\n",
      "  begin \n",
      "      NewvarNode(:(l::Float64)) # line 9:\n",
      "      sumx::Int64 = $(Expr(:invoke, MethodInstance for _mapreduce(::Base.#identity, ::Base.#+, ::IndexLinear, ::Array{Int64,1}), :(Base._mapreduce), :(Base.identity), :(Base.+), :($(QuoteNode(IndexLinear()))), :(x))) # line 10:\n",
      "      sumα::Float64 = $(Expr(:invoke, MethodInstance for _mapreduce(::Base.#identity, ::Base.#+, ::IndexLinear, ::Array{Float64,1}), :(Base._mapreduce), :(Base.identity), :(Base.+), :($(QuoteNode(IndexLinear()))), :(α))) # line 11:\n",
      "      unless (sumx::Int64 === 0)::Bool goto 15\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location float.jl == 476\n",
      "      fy@_13::Float64 = (Base.sitofp)(Float64, 0)::Float64\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      #temp#@_10::Bool = (Base.and_int)((Base.and_int)((Base.eq_float)(sumα::Float64, fy@_13::Float64)::Bool, (Base.ne_float)(fy@_13::Float64, 9.223372036854776e18)::Bool)::Bool, (0 === (Base.fptosi)(Int64, fy@_13::Float64)::Int64)::Bool)::Bool\n",
      "      goto 17\n",
      "      15: \n",
      "      #temp#@_10::Bool = false\n",
      "      17: \n",
      "      unless #temp#@_10::Bool goto 21 # line 12:\n",
      "      return (Base.sitofp)(Float64, 0)::Float64\n",
      "      21:  # line 13:\n",
      "      unless (Base.slt_int)(0, sumx::Int64)::Bool goto 31\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location float.jl == 476\n",
      "      fy@_14::Float64 = (Base.sitofp)(Float64, 0)::Float64\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      #temp#@_11::Bool = (Base.and_int)((Base.and_int)((Base.eq_float)(sumα::Float64, fy@_14::Float64)::Bool, (Base.ne_float)(fy@_14::Float64, 9.223372036854776e18)::Bool)::Bool, (0 === (Base.fptosi)(Int64, fy@_14::Float64)::Int64)::Bool)::Bool\n",
      "      goto 33\n",
      "      31: \n",
      "      #temp#@_11::Bool = false\n",
      "      33: \n",
      "      unless #temp#@_11::Bool goto 37 # line 14:\n",
      "      return (Base.neg_float)(Main.Inf)::Float64\n",
      "      37:  # line 16:\n",
      "      SSAValue(7) = $(Expr(:invoke, MethodInstance for lfact(::Int64), :(Main.lfact), :(sumx)))\n",
      "      SSAValue(4) = (Base.add_float)((Base.sitofp)(Float64, sumx::Int64)::Float64, sumα::Float64)::Float64\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location math.jl lgamma 419\n",
      "      SSAValue(6) = $(Expr(:foreigncall, (\"lgamma\", \"libopenlibm\"), Float64, svec(Float64), SSAValue(4), 0))\n",
      "      # meta: location math.jl nan_dom_err 300\n",
      "      unless (Base.and_int)((Base.ne_float)(SSAValue(6), SSAValue(6))::Bool, (Base.not_int)((Base.ne_float)(SSAValue(4), SSAValue(4))::Bool)::Bool)::Bool goto 48\n",
      "      #temp#@_16::Float64 = (Base.Math.throw)($(QuoteNode(DomainError())))\u001b[1m\u001b[91m::Union{}\u001b[39m\u001b[22m\n",
      "      goto 50\n",
      "      48: \n",
      "      #temp#@_16::Float64 = SSAValue(6)\n",
      "      50: \n",
      "      # meta: pop location\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location math.jl lgamma 419\n",
      "      SSAValue(3) = $(Expr(:foreigncall, (\"lgamma\", \"libopenlibm\"), Float64, svec(Float64), :(sumα), 0))\n",
      "      # meta: location math.jl nan_dom_err 300\n",
      "      unless (Base.and_int)((Base.ne_float)(SSAValue(3), SSAValue(3))::Bool, (Base.not_int)((Base.ne_float)(sumα::Float64, sumα::Float64)::Bool)::Bool)::Bool goto 61\n",
      "      #temp#@_15::Float64 = (Base.Math.throw)($(QuoteNode(DomainError())))\u001b[1m\u001b[91m::Union{}\u001b[39m\u001b[22m\n",
      "      goto 63\n",
      "      61: \n",
      "      #temp#@_15::Float64 = SSAValue(3)\n",
      "      63: \n",
      "      # meta: pop location\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      l::Float64 = (Base.add_float)((Base.sub_float)(SSAValue(7), #temp#@_16::Float64)::Float64, #temp#@_15::Float64)::Float64\n",
      "      68:  # line 18:\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location abstractarray.jl eachindex 764\n",
      "      # meta: location abstractarray.jl indices1 71\n",
      "      # meta: location abstractarray.jl indices 64\n",
      "      SSAValue(10) = (Base.arraysize)(x::Array{Int64,1}, 1)::Int64\n",
      "      # meta: pop location\n",
      "      # meta: pop location\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      SSAValue(20) = (Base.select_value)((Base.slt_int)(SSAValue(10), 0)::Bool, 0, SSAValue(10))::Int64\n",
      "      #temp#@_5::Int64 = 1\n",
      "      81: \n",
      "      unless (Base.not_int)((#temp#@_5::Int64 === (Base.add_int)(SSAValue(20), 1)::Int64)::Bool)::Bool goto 147\n",
      "      SSAValue(21) = #temp#@_5::Int64\n",
      "      SSAValue(22) = (Base.add_int)(#temp#@_5::Int64, 1)::Int64\n",
      "      i::Int64 = SSAValue(21)\n",
      "      #temp#@_5::Int64 = SSAValue(22) # line 19:\n",
      "      SSAValue(11) = (Base.arrayref)(α::Array{Float64,1}, i::Int64)::Float64\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location float.jl == 476\n",
      "      fy@_17::Float64 = (Base.sitofp)(Float64, 0)::Float64\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      unless (Base.and_int)((Base.and_int)((Base.eq_float)(SSAValue(11), fy@_17::Float64)::Bool, (Base.ne_float)(fy@_17::Float64, 9.223372036854776e18)::Bool)::Bool, (0 === (Base.fptosi)(Int64, fy@_17::Float64)::Int64)::Bool)::Bool goto 97\n",
      "      #temp#@_12::Bool = (Base.slt_int)(0, (Base.arrayref)(x::Array{Int64,1}, i::Int64)::Int64)::Bool\n",
      "      goto 99\n",
      "      97: \n",
      "      #temp#@_12::Bool = false\n",
      "      99: \n",
      "      unless #temp#@_12::Bool goto 103 # line 20:\n",
      "      return (Base.neg_float)(Main.Inf)::Float64\n",
      "      103:  # line 21:\n",
      "      SSAValue(12) = (Base.arrayref)(α::Array{Float64,1}, i::Int64)::Float64\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location operators.jl > 216\n",
      "      # meta: location float.jl < 482\n",
      "      fx::Float64 = (Base.sitofp)(Float64, 0)::Float64\n",
      "      # meta: pop location\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      unless (Base.or_int)((Base.lt_float)(fx::Float64, SSAValue(12))::Bool, (Base.and_int)((Base.eq_float)(fx::Float64, SSAValue(12))::Bool, (Base.or_int)((Base.eq_float)(fx::Float64, 9.223372036854776e18)::Bool, (Base.slt_int)(0, (Base.fptosi)(Int64, fx::Float64)::Int64)::Bool)::Bool)::Bool)::Bool goto 145 # line 22:\n",
      "      SSAValue(19) = $(Expr(:invoke, MethodInstance for lfact(::Int64), :(Main.lfact), :((Base.arrayref)(x, i)::Int64)))\n",
      "      SSAValue(16) = (Base.add_float)((Base.sitofp)(Float64, (Base.arrayref)(x::Array{Int64,1}, i::Int64)::Int64)::Float64, (Base.arrayref)(α::Array{Float64,1}, i::Int64)::Float64)::Float64\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location math.jl lgamma 419\n",
      "      SSAValue(18) = $(Expr(:foreigncall, (\"lgamma\", \"libopenlibm\"), Float64, svec(Float64), SSAValue(16), 0))\n",
      "      # meta: location math.jl nan_dom_err 300\n",
      "      unless (Base.and_int)((Base.ne_float)(SSAValue(18), SSAValue(18))::Bool, (Base.not_int)((Base.ne_float)(SSAValue(16), SSAValue(16))::Bool)::Bool)::Bool goto 124\n",
      "      #temp#@_20::Float64 = (Base.Math.throw)($(QuoteNode(DomainError())))\u001b[1m\u001b[91m::Union{}\u001b[39m\u001b[22m\n",
      "      goto 126\n",
      "      124: \n",
      "      #temp#@_20::Float64 = SSAValue(18)\n",
      "      126: \n",
      "      # meta: pop location\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      SSAValue(13) = (Base.arrayref)(α::Array{Float64,1}, i::Int64)::Float64\n",
      "      $(Expr(:inbounds, false))\n",
      "      # meta: location math.jl lgamma 419\n",
      "      SSAValue(15) = $(Expr(:foreigncall, (\"lgamma\", \"libopenlibm\"), Float64, svec(Float64), SSAValue(13), 0))\n",
      "      # meta: location math.jl nan_dom_err 300\n",
      "      unless (Base.and_int)((Base.ne_float)(SSAValue(15), SSAValue(15))::Bool, (Base.not_int)((Base.ne_float)(SSAValue(13), SSAValue(13))::Bool)::Bool)::Bool goto 138\n",
      "      #temp#@_19::Float64 = (Base.Math.throw)($(QuoteNode(DomainError())))\u001b[1m\u001b[91m::Union{}\u001b[39m\u001b[22m\n",
      "      goto 140\n",
      "      138: \n",
      "      #temp#@_19::Float64 = SSAValue(15)\n",
      "      140: \n",
      "      # meta: pop location\n",
      "      # meta: pop location\n",
      "      $(Expr(:inbounds, :pop))\n",
      "      l::Float64 = (Base.add_float)(l::Float64, (Base.sub_float)((Base.add_float)((Base.neg_float)(SSAValue(19))::Float64, #temp#@_20::Float64)::Float64, #temp#@_19::Float64)::Float64)::Float64\n",
      "      145: \n",
      "      goto 81\n",
      "      147:  # line 25:\n",
      "      return l::Float64\n",
      "  end::Float64\n"
     ]
    }
   ],
   "source": [
    "@code_warntype dirmult_logpdf(ones(Int, 5), ones(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Read in `optdigits.tra`, the training set of 3823 handwritten digits. Each row contains the 64 counts of a digit and the last element (65th element) indicates what digit it is. For grading purpose, evaluate the total log-likelihood of this data at parameter values $\\alpha=(1,\\ldots,1)$ using your function in Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  550k  100  550k    0     0  2211k      0 --:--:-- --:--:-- --:--:-- 2219k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3823×65 Array{Int64,2}:\n",
       " 0  1   6  15  12   1   0  0  0  7  16  …  0  0  0   6  14   7   1   0  0  0\n",
       " 0  0  10  16   6   0   0  0  0  7  16     0  0  0  10  16  15   3   0  0  0\n",
       " 0  0   8  15  16  13   0  0  0  1  11     0  0  0   9  14   0   0   0  0  7\n",
       " 0  0   0   3  11  16   0  0  0  0   5     0  0  0   0   1  15   2   0  0  4\n",
       " 0  0   5  14   4   0   0  0  0  0  13     0  0  0   4  12  14   7   0  0  6\n",
       " 0  0  11  16  10   1   0  0  0  4  16  …  3  0  0  10  16  16  16  16  6  2\n",
       " 0  0   1  11  13  11   7  0  0  0   9     0  0  0   1  13   5   0   0  0  5\n",
       " 0  0   8  10   8   7   2  0  0  1  15     0  0  0   4  13   8   0   0  0  5\n",
       " 0  0  15   2  14  13   2  0  0  0  16     0  0  0  10  12   5   0   0  0  0\n",
       " 0  0   3  13  13   2   0  0  0  6  16     0  0  0   3  15  11   6   0  0  8\n",
       " 0  0   6  14  14  16  16  8  0  0   7  …  0  0  0  10  12   0   0   0  0  7\n",
       " 0  0   0   3  16  11   1  0  0  0   0     0  0  0   0   2  14  14   1  0  1\n",
       " 0  0   0   4  13  16  16  3  0  0   8     0  0  0   0   5  15   4   0  0  9\n",
       " ⋮                  ⋮                ⋮  ⋱  ⋮                 ⋮              \n",
       " 0  0   0   0   7  11   1  0  0  0   0     0  0  0   2   0   7  11   0  0  1\n",
       " 0  0   0   6  13   0   0  0  0  0   3     0  0  0   0   6   9   0   0  0  4\n",
       " 0  0   0   6   8   0   0  0  0  0   2     0  0  1   4   9   8   0   0  0  4\n",
       " 0  0   9  16   6   0   0  0  0  2  14     0  0  0  10  13   1   0   0  0  8\n",
       " 0  0   9  16  12   1   0  0  0  3  16  …  0  0  0   8  16  16  16   8  0  9\n",
       " 0  1  10  16  16   4   0  0  0  8  13     0  0  2  13  16  12   5   0  0  3\n",
       " 0  0   6  16  11   0   0  0  0  1  16     0  0  1   7  14  16  12   1  0  9\n",
       " 0  0   5  13  11   2   0  0  0  2  15     0  0  0   8  13  15  10   1  0  9\n",
       " 0  0   0   1  12   1   0  0  0  0   0     0  0  0   0   4   9   0   0  0  4\n",
       " 0  0   3  15   0   0   0  0  0  0  11  …  0  0  0   4  14  16   9   0  0  6\n",
       " 0  0   6  16   2   0   0  0  0  0  15     0  0  0   5  16  16  16   5  0  6\n",
       " 0  0   2  15  16  13   1  0  0  0   3     0  0  0   4  14   1   0   0  0  7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in optdigits.tra\n",
    "if !isfile(\"optdigits.tra\")\n",
    "    download(\"http://hua-zhou.github.io/teaching/\" * \n",
    "        \"biostatm280-2018spring/hw/hw4/optdigits.tra\",\n",
    "        \"optdigits.tra\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3823-element Array{Float64,1}:\n",
       " -165.188\n",
       " -176.23 \n",
       " -167.774\n",
       " -165.564\n",
       " -157.79 \n",
       " -176.071\n",
       " -158.423\n",
       " -159.258\n",
       " -174.302\n",
       " -178.407\n",
       " -171.294\n",
       " -169.383\n",
       " -175.753\n",
       "    ⋮    \n",
       " -160.49 \n",
       " -158.633\n",
       " -156.935\n",
       " -171.975\n",
       " -177.638\n",
       " -169.735\n",
       " -158.423\n",
       " -159.465\n",
       " -159.877\n",
       " -169.735\n",
       " -173.149\n",
       " -155.411"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = readcsv(\"optdigits.tra\", Int)\n",
    "digit = opt[:, end]\n",
    "count = opt[:, 1:64]'\n",
    "# total log-likelihood of this data at parameter values\n",
    "loglkh = dirmult_logpdf(count, ones(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-638817.993292528"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loglkh = sum(loglkh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "Derive the score function $\\nabla L(\\alpha)$, observed information matrix $-d^2L(\\alpha)$, and Fisher information matrix $\\mathbf{E}[-d^2L(\\alpha)]$ for the Dirichlet-multinomial distribution.\n",
    "\n",
    "Comment on why Fisher scoring method is inefficient for computing MLE in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score: \n",
    "$$\\nabla L(\\theta) = \\begin{pmatrix}\n",
    "  \\frac{\\partial L(\\theta)}{\\partial \\theta_1} \\\\\n",
    "  \\vdots \\\\\n",
    "  \\frac{\\partial L(\\theta)}{\\partial \\theta_p}\n",
    "  \\end{pmatrix} $$\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\alpha_j} L(\\alpha) = \\frac{\\partial}{\\partial \\alpha_j} (\\sum_{i=1}^n \\sum_{j=1}^d [\\ln \\Gamma(\\alpha_j + x_{ij}) - \\ln \\Gamma(\\alpha_j)] - \\sum_{i=1}^n [\\ln \\Gamma(|\\alpha|+|\\mathbf{x}_i|) - \\ln \\Gamma(|\\alpha|)] )$$\n",
    "$$ = \\sum_{i=1}^n [\\psi(x_{ij}+\\alpha_j) - \\psi(\\alpha_j)] - \\sum_{i=1}^n [\\psi(|\\mathbf{x}_i|+|\\alpha|) - \\psi(|\\alpha|)]$$\n",
    "where $\\psi(x) = [\\ln \\Gamma(x)]' = \\Gamma'(x)/\\Gamma(x)$\n",
    "\n",
    "The observed information matrix:\n",
    "$$ \\nabla^2 L(\\theta) = d^2 L(\\theta) = \\begin{pmatrix}\n",
    "  \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_1 \\partial \\theta_1} & \\dots & \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_1 \\partial \\theta_p} \\\\\n",
    "  \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_p \\partial \\theta_1} & \\dots & \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_p \\partial \\theta_p}\n",
    "  \\end{pmatrix}$$\n",
    "  \n",
    "$$ [- d^2 L(\\alpha)] = \\sum_{i=1}^n [\\psi'(\\alpha_j) -\\psi'(x_{ij}+\\alpha_j)] - \\sum_{i=1}^n [ \\psi'(|\\alpha|) + \\psi'(|\\mathbf{x}_i|+|\\alpha|)] $$\n",
    "\n",
    "To express the $[- d^2 L(\\alpha)]$ simpler, observed information matrix can be shown as:\n",
    "$$[- d^2 L(\\alpha)] = \\mathbf{D} - c \\mathbf{1} \\mathbf{1}^T,$$\n",
    "where $ d_j = \\sum_{i=1}^n \\sum_{k=0}^{x_{ij}-1} \\frac{1}{(\\alpha_j + k)^2} $\n",
    "and $ c = \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\frac{1}{(|\\alpha|+k)^2}$\n",
    "\n",
    "The expected information matrix: \n",
    "$$\\mathbf{E}[-d^2L(\\alpha)] = \\mathbf{E}[\\mathbf{D} - c \\mathbf{1} \\mathbf{1}^T] = \\mathbf{E}(\\mathbf{D}) - c \\mathbf{1}_d \\mathbf{1}_d^T $$\n",
    "$$ \\mathbf{E}(d_j) = \\mathbf{E}[\\sum_{i=1}^n \\sum_{k=0}^{x_{ij}-1} \\frac{1}{(\\alpha_j + k)^2}] = \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\frac{\\mathbf{P}(X_{ij}>k)}{(\\alpha_j+k)^2},$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "What structure does the observed information matrix possess that can facilitate the evaluation of the Newton direction? Is the observed information matrix always positive definite? What remedy can we take if it fails to be positive definite? (Hint: HW1 Q6.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the result of HW1 Q6 \n",
    "\n",
    "Sherman-Morrison formula: $(\\mathbf{A} + \\mathbf{u} \\mathbf{u}^T)^{-1} = \\mathbf{A}^{-1} - \\frac{1}{1 + \\mathbf{u}^T \\mathbf{A}^{-1} \\mathbf{u}} \\mathbf{A}^{-1} \\mathbf{u} \\mathbf{u}^T \\mathbf{A}^{-1}$; \n",
    "Determinant formula: $\\text{det}(\\mathbf{A} + \\mathbf{U} \\mathbf{V}^T) = \\text{det}(\\mathbf{A}) \\text{det}(\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})$\n",
    "\n",
    "$$[-d^2L(\\boldsymbol{\\alpha})]^{-1} = \\boldsymbol{D}^{-1} + \\frac{1}{c^{-1} - \\sum_j d_j^{-1}} \\boldsymbol{D}^{-1} \\boldsymbol{1} \\boldsymbol{1}^T \\boldsymbol{D}^{-1} $$\n",
    "$$ \\text{det}[-d^2L(\\boldsymbol{\\alpha})] = \\left( \\prod_j d_j \\right) \\left(1 - c \\sum_j d_j^{-1} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "Discuss how to choose a good starting point. Implement this as the default starting value in your function below. (Hint: Method of moment estimator may furnish a good starting point.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8\n",
    "\n",
    "Write a function for finding MLE of Dirichlet-multinomial distribution given iid observations $\\mathbf{x}_1,\\ldots,\\mathbf{x}_n$, using the Newton's method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirmult_newton"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dirmult_newton(X)\n",
    "\n",
    "Find the MLE of Dirichlet-multinomial distribution using Newton's method.\n",
    "\n",
    "# Argument\n",
    "* `X`: an `n`-by-`d` matrix of counts; each column is one data point.\n",
    "\n",
    "# Optional argument  \n",
    "* `alpha0`: a `d` vector of starting point (optional). \n",
    "* `maxiters`: the maximum allowable Newton iterations (default 100). \n",
    "* `tolfun`: the tolerance for  relative change in objective values (default 1e-6). \n",
    "\n",
    "# Output\n",
    "* `maximum`: the log-likelihood at MLE.   \n",
    "* `estimate`: the MLE. \n",
    "* `gradient`: the gradient at MLE. \n",
    "* `hessian`: the Hessian at MLE. \n",
    "* `se`: a `d` vector of standard errors. \n",
    "* `iterations`: the number of iterations performed.\n",
    "\"\"\"\n",
    "function dirmult_newton(X::Matrix; α0::Vector = nothing, \n",
    "            maxiters::Int = 100, tolfun::Float64 = 1e-6)\n",
    "    \n",
    "    # set default starting point from Q7\n",
    "    \n",
    "    # Newton loop\n",
    "    for iter in 1:maxiters\n",
    "        # evaluate gradient (score)\n",
    "        \n",
    "        # compute Newton's direction\n",
    "        \n",
    "        # line search loop\n",
    "        for lsiter in 1:10\n",
    "            # step halving\n",
    "        end\n",
    "        \n",
    "        # check convergence criterion\n",
    "        if abs(logl - loglold) < tolfun * (abs(loglold) + 1)\n",
    "            break;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # compute logl, gradient, Hessian from final iterate\n",
    "    \n",
    "    # output\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9\n",
    "\n",
    "Read in `optdigits.tra`, the training set of 3823 handwritten digits. Find the MLE for the subset of digit 0, digit 1, ..., and digit 9 separately using your function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10\n",
    "\n",
    "As $\\alpha / |\\alpha| \\to \\mathbf{p}$, the Dirichlet-multinomial distribution converges to a multinomial with parameter $\\mathbf{p}$. Therefore multinomial can be considered as a special Dirichlet-multinomial with $|\\alpha|=\\infty$. Perform a likelihood ratio test (LRT) whether Dirichlet-multinomial offers a better fit than multinomial for digits 0, 1, ..., 9 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11\n",
    "\n",
    "Now we can construct a simple Bayesian rule for handwritten digits recognition:\n",
    "$$\n",
    "\t\\mathbf{x}\t\\mapsto \\arg \\max_k \\widehat \\pi_k f(x|\\widehat \\alpha_k).\n",
    "$$\n",
    "Here we can use the proportion of digit $k$ in the training set as the prior probability $\\widehat \\pi_k$. Report the performance of your classifier on the test set of 1797 digits in `optdigits.tes`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "65px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
